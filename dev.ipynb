{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "import snowflake.snowpark.modin.plugin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "import re\n",
    "from itertools import product\n",
    "from pprint import pp\n",
    "from math import ceil\n",
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = ['Dentist', 'CPA', 'Plumber']\n",
    "locations = ['Olathe,KS', 'Overland Park, KS', 'Leawood,KS', 'Kansas City,KS', 'Kansas City,MO', 'Lees Summit,MO', 'Independence,MO', 'Blue Springs,MO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'search_terms': 'CPA',\n",
    "          'geo_location_terms': quote_plus('Lees Summit,MO')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('http://yellowpages.com/search', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"showing-count\">Showing 1-30 of 434<span class=\"result-info\">More info</span></span>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = resp.content\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "res = soup.findAll(class_ = 'info')\n",
    "soup.find_all(class_ = 'showing-count')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_name = r\">[A-Z a-z0-9.,&;\\-]+<\"\n",
    "bus_add = r\">[A-Z a-z0-9.,&;]+<\"\n",
    "bus_phone = r\">[0-9() -]+<\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['8162514575']\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = re.findall(bus_phone,str(res[2].findAll(class_ = 'phones phone primary')))\n",
    "re.sub(r'[<>() -]', '', str(temp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Bad owner or permissions on C:\\Users\\bjornsonm\\.snowflake\\connections.toml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://ffbkc.okta.com/app/snowflake/exka3eb1paQUAt90P4x7/sso/saml?SAMLRequest=lZJRb9owGEX%2FSuQ9J05CWFsLqAKoKxvQAAFNfTOJAx6OnflzCO2vnwll6h5aaW%2BRc6597Pv17k%2BlcI5MA1eyjwLPRw6Tmcq53PXROn1wb5EDhsqcCiVZH70wQPeDHtBSVCSuzV4u2e%2BagXHsRhJI%2B6OPai2JosCBSFoyICYjq3g2JaHnk0orozIl0LvI5wkKwLSxhtdIDtzq7Y2pCMZN03hNx1N6h0Pf97F%2Fhy11Rr5c%2BZO90wd8gP3ozFvC4smb25DLyxN8prW9QEAe0zRxk6dVipz4qjpSEuqS6RXTR56x9XJ6EQBrsJg%2F%2F1gsJm6yfBp7IFVTCHpgmSqr2tgNPfuFC5ZjoXbc3nky7qPqwHM9P%2BYi%2Byb1PupOU7oZZq%2Fhz83jLzqMlebFqMO%2Fzr7Hs1F%2Bu86Qs7mWGp5LnQDUbCLPVRq75IeRG%2Fhu2E2DDvG7pBN5NzfRM3LGtkouqWmTV9%2Bi2B4yTx0MbdVoVeG%2F1pidDrTDtkFFF%2BvY3PlJdLrBAAqfe0WXUSHt8XrwHw%2FQw%2B%2BDbwM3tx1MxokSPHtxHpQuqfm4osAL2hWeu0WLElZSLuI81wzAViWEakaaUWPn2uiaITy4nPrvZA%2F%2BAA%3D%3D&RelayState=ver%3A1-hint%3A13809346368811122-ETMsDgAAAZLDyEQ2ABRBRVMvQ0JDL1BLQ1M1UGFkZGluZwEAABAAEM7zQQXVWcTB9pnLMD%2Byh%2BcAAACAA88UAS7kvc64K0wBFi3x8ycCBpHFzRG4lPiK%2BvafacBequ2DMq%2FUFUWXESgMXzvnyxAa8yKM3jhnBVVP9oipz7%2FILzUSwq%2FpJy3sGvLdPL4jwIS7DUHp%2BTZL6lj8Evx6hDvoOqo0fRKakJf40c3HdBYkzwIhl8zs%2FTtM4lzW%2BGQAFIV1sodxmjQU30HtHJKbQu%2B%2B1qeF to authenticate...\n"
     ]
    }
   ],
   "source": [
    "connection_parameters = {}\n",
    "connection_parameters[\"account\"] = 'qnzkqqi-prod'\n",
    "connection_parameters[\"database\"] = 'SANDBOXES'\n",
    "connection_parameters[\"schema\"] = 'MBJORNSON'\n",
    "connection_parameters[\"warehouse\"] = 'COMPUTE_WH'\n",
    "connection_parameters[\"role\"] = 'SYSADMIN'\n",
    "connection_parameters[\"user\"] = 'mbjornson'\n",
    "connection_parameters[\"Authenticator\"] = \"externalbrowser\"\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame([{'BUSINESS_NAME': re.sub(r'[<>]', '',re.findall(bus_name,str(x.findAll(class_ = 'business-name')))[0]) if re.findall(bus_name,str(x.findAll(class_ = 'business-name'))) else '' ,\n",
    "                 'STREET': re.sub(r'[<>]', '',re.findall(bus_add,str(x.findAll(class_ = 'street-address')))[0]) if re.findall(bus_add,str(x.findAll(class_ = 'street-address'))) else '' ,\n",
    "                 'LOCALITY':re.sub(r'[<>]', '',re.findall(bus_add,str(x.findAll(class_ = 'locality')))[0]) if re.findall(bus_add,str(x.findAll(class_ = 'locality'))) else '' ,\n",
    "                 'PHONE':re.sub(r'[<>() -]', '',re.findall(bus_phone,str(x.findAll(class_ = 'phones phone primary')))[0]) if re.findall(bus_phone,str(x.findAll(class_ = 'phones phone primary'))) else '', \n",
    "                 'SEARCH_TERM': params['search_terms']\n",
    "                } for x in res if x.findAll(class_ = 'street-address') != []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp['city'] = temp['LOCALITY'].apply(lambda x: x.split(',')[0])\n",
    "temp['state'] = temp['LOCALITY'].apply(lambda x: x.split(',')[1].split()[0])\n",
    "temp['zip'] = temp['LOCALITY'].apply(lambda x: x.split(',')[1].split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['LOCALITY'] = temp['LOCALITY'].str.split(',')\n",
    "temp['city'] = temp['LOCALITY'].apply(lambda x: x[0])\n",
    "temp['state'] = temp['LOCALITY'].apply(lambda x: x[1].split()[0])\n",
    "temp['zip'] = temp['LOCALITY'].apply(lambda x: x[1].split()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['LOCALITY'] = temp['LOCALITY'].apply(lambda s: re.sub(r'(?<=, [A-Z]{2}) ', ', ', s))\n",
    "temp['LOCALITY'] = temp['LOCALITY'].str.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def YP_SCRAPER(session:Session, professions:list, locations:list) -> pd.DataFrame:\n",
    "    searches = [(x,y) for x in professions for y in locations]\n",
    "    results = []\n",
    "    df = pd.DataFrame()\n",
    "    for s in searches:\n",
    "        params = {'search_terms': quote_plus(s[0]),\n",
    "          'geo_location_terms': quote_plus(s[1]), \n",
    "          'page' : 1\n",
    "        }\n",
    "        results = []\n",
    "        resp = requests.get('http://yellowpages.com/search', params=params)\n",
    "        content = resp.content\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        res_ct = ceil(int(re.findall(\"(?<=of )[0-9]+\", str(soup.find_all(class_ = 'showing-count')))[0])/30) if re.findall(\"(?<=of )[0-9]+\", str(soup.find_all(class_ = 'showing-count')))[0] != [] else 0\n",
    "        #int(re.findall(\"(?<=[0-9]-)[0-9]+\", str(soup.find_all(class_ = 'showing-count')))[0])\n",
    "        while params['page'] < 4: #res_ct:\n",
    "          if params['page'] >1:\n",
    "            resp = requests.get('http://yellowpages.com/search', params=params)\n",
    "            content = resp.content\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "          res = soup.findAll(class_ = 'info')\n",
    "          params['page'] +=1\n",
    "          #print(params['page'])\n",
    "          results += res\n",
    "        temp = pd.DataFrame([{'business_name': re.sub(r'[<>]', '',re.findall(bus_name,str(x.findAll(class_ = 'business-name')))[0]) if re.findall(bus_name,str(x.findAll(class_ = 'business-name'))) else '' ,\n",
    "                 'street_address': re.sub(r'[<>]', '',re.findall(bus_add,str(x.findAll(class_ = 'street-address')))[0]) if re.findall(bus_add,str(x.findAll(class_ = 'street-address'))) else '' ,\n",
    "                 'locality':re.sub(r'[<>]', '',re.findall(bus_add,str(x.findAll(class_ = 'locality')))[0]) if re.findall(bus_add,str(x.findAll(class_ = 'locality'))) else '' ,\n",
    "                 'phone':re.sub(r'[<>() -]', '',re.findall(bus_phone,str(x.findAll(class_ = 'phones phone primary')))[0]) if re.findall(bus_phone,str(x.findAll(class_ = 'phones phone primary'))) else '', \n",
    "                 'search_term': params['search_terms']\n",
    "                } for x in res if x.findAll(class_ = 'street-address') != []])\n",
    "        df = pd.concat([df, temp])\n",
    "    df.to_snowflake('test_table', if_exists='replace', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = YP_SCRAPER(session, professions, locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_snowflake('test_table', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(''' \n",
    "            select \n",
    "            *\n",
    "            from sandboxes.information_schema.stages'''\n",
    "            ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yp_scrapper_proc(session:Session, professions:list, locations:list) -> str:\n",
    "    import pandas\n",
    "    df = YP_SCRAPER(professions, locations)\n",
    "    session.write_pandas(df, 'YP_SCRAPE', overwrite=True)\n",
    "    return 'finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_scrapper_sproc = session.sproc.register(func=yp_scrapper_proc, \n",
    "                                             name='yp_scrapper_sproc', \n",
    "                                             is_permanent=True, \n",
    "                                             replace=True, \n",
    "                                             stage_location='@SNDBX', \n",
    "                                             packages= ['snowflake-snowpark-python', 'pandas', 'itertools','joblib'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
